---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
spec:
  interval: 1h
  chart:
    spec:
      chart: kube-prometheus-stack
      version: 80.13.3
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: observability
  values:
    grafana:
      enabled: false

    # This cluster is kube-proxy-free (Cilium).
    kubeProxy:
      enabled: false

    # Avoid scraping control-plane components that are often not exposed by default.
    kubeEtcd:
      enabled: false
    kubeControllerManager:
      enabled: false
    kubeScheduler:
      enabled: false

    prometheus:
      prometheusSpec:
        retention: 15d
        externalLabels:
          cluster: homelab-cluster
        podMetadata:
          annotations:
            reloader.stakater.com/auto: "true"
        # Accept remote_write in-cluster (used by Tempo metrics-generator).
        enableRemoteWriteReceiver: true
        # Remote write to Grafana Mimir for long-term, horizontally scalable metrics storage.
        remoteWrite:
          - url: http://mimir-distributed-gateway.observability.svc.cluster.local/api/v1/push
            headers:
              X-Scope-OrgID: homelab
            writeRelabelConfigs:
              # Keep long-term metrics useful while avoiding obvious cardinality traps.
              # (These labels are high-churn and rarely needed for long-term trends.)
              - action: labeldrop
                regex: "pod_uid|container_id|image_id"
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelectorNilUsesHelmValues: false
        probeSelectorNilUsesHelmValues: false
        ruleSelectorNilUsesHelmValues: false
        serviceMonitorSelector: {}
        podMonitorSelector: {}
        probeSelector: {}
        ruleSelector: {}
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: longhorn
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 50Gi
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: "2"
            memory: 4Gi

    prometheusOperator:
      podAnnotations:
        reloader.stakater.com/auto: "true"
      resources:
        requests:
          cpu: 100m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi

    kube-state-metrics:
      podAnnotations:
        reloader.stakater.com/auto: "true"
      resources:
        requests:
          cpu: 50m
          memory: 128Mi
        limits:
          cpu: 200m
          memory: 256Mi

    nodeExporter:
      resources:
        requests:
          cpu: 10m
          memory: 64Mi
        limits:
          cpu: 50m
          memory: 128Mi

    prometheus-node-exporter:
      podAnnotations:
        reloader.stakater.com/auto: "true"

    alertmanager:
      config:
        global:
          resolve_timeout: 5m

        route:
          receiver: "null"
          group_by: [alertname, namespace, severity]
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 12h
          routes:
            # Keep the always-firing Watchdog out of your inbox.
            - receiver: "null"
              matchers:
                - alertname="Watchdog"

            - receiver: discord
              matchers:
                - severity=~"warning|critical"
                - alertname!="InfoInhibitor"

        receivers:
          - name: "null"

          - name: discord
            slack_configs:
              - api_url_file: "/etc/alertmanager/secrets/alertmanager-discord/webhook_url"
                send_resolved: true
                title: "[{{ .Status | toUpper }}] {{ .CommonLabels.alertname }} ({{ .CommonLabels.namespace }})"
                text: "{{ range .Alerts }}*{{ .Annotations.summary }}*\n{{ .Annotations.description }}\n{{ end }}"

        inhibit_rules:
          - source_matchers:
              - severity="critical"
            target_matchers:
              - severity="warning"
            equal: [namespace, alertname]

      alertmanagerSpec:
        podMetadata:
          annotations:
            reloader.stakater.com/auto: "true"
        secrets:
          - alertmanager-discord
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
        storage:
          volumeClaimTemplate:
            spec:
              storageClassName: longhorn
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 5Gi
