---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: tempo
spec:
  interval: 1h
  chart:
    spec:
      chart: tempo
      version: 1.24.1
      sourceRef:
        kind: HelmRepository
        name: grafana-charts-tempo
        namespace: observability
  values:
    podAnnotations:
      reloader.stakater.com/auto: "true"

    tempo:
      extraEnvFrom:
        - secretRef:
            name: observability-s3

      # The chart defaults this to 1024, which can OOM with a 1Gi limit.
      memBallastSizeMbs: 256

      # Expand $VAR/${VAR} in the generated config using the container env.
      # This keeps S3 credentials/endpoints out of the HelmRelease spec.
      extraArgs:
        config.expand-env: true

      # Disabled for small clusters; re-enable later if you want service graphs/span-metrics.
      metricsGenerator:
        enabled: true
        # Prometheus remote_write receiver (enabled in kube-prometheus-stack HelmRelease).
        remoteWriteUrl: http://kube-prometheus-stack-prometheus.observability.svc.cluster.local:9090/api/v1/write
        processor:
          service_graphs:
            wait: 10s
            max_items: 2000
          span_metrics:
            enable_target_info: true
        storage:
          path: /tmp/tempo
        traces_storage:
          path: /tmp/traces

      overrides:
        defaults:
          metrics_generator:
            processors:
              - service-graphs
              - span-metrics

      resources:
        requests:
          cpu: 100m
          memory: 768Mi
        limits:
          cpu: "1"
          memory: 1500Mi
      # Store traces in S3-compatible object storage.
      storage:
        trace:
          backend: s3
          s3:
            bucket: tempo
            endpoint: ${S3_ENDPOINT}
            region: ${S3_REGION}
            access_key: ${S3_ACCESS_KEY_ID}
            secret_key: ${S3_SECRET_ACCESS_KEY}
            insecure: true
