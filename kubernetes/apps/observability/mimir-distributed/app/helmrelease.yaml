---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: mimir-distributed
spec:
  interval: 1h
  chart:
    spec:
      chart: mimir-distributed
      version: 6.0.5
      sourceRef:
        kind: HelmRepository
        name: grafana-charts-mimir
        namespace: observability

  # Patch rendered resources without forking the upstream chart.
  # Kafka PVC growth is dominated by broker log retention; the chart defaults to 24h.
  postRenderers:
    - kustomize:
        patches:
          - target:
              group: apps
              version: v1
              kind: StatefulSet
              name: mimir-distributed-kafka
            patch: |-
              apiVersion: apps/v1
              kind: StatefulSet
              metadata:
                name: mimir-distributed-kafka
              spec:
                template:
                  spec:
                    containers:
                      - name: kafka
                        env:
                          # IMPORTANT: the embedded Kafka defaults to 24h retention.
                          # Enforce retention & segment rollover here so it actually reaches the broker.
                          # (values.kafka.extraEnv is chart-dependent and may not be wired for this container.)
                          - name: KAFKA_LOG_RETENTION_MS
                            value: "7200000" # 2h
                          - name: KAFKA_LOG_RETENTION_BYTES
                            value: "33554432" # 32Mi (per-partition)
                          - name: KAFKA_LOG_SEGMENT_MS
                            value: "900000" # 15m
                          - name: KAFKA_LOG_SEGMENT_BYTES
                            value: "134217728" # 128Mi
                          - name: KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS
                            value: "300000"
                          - name: KAFKA_OFFSETS_RETENTION_MINUTES
                            value: "1440" # 1d
  values:
    podAnnotations:
      reloader.stakater.com/auto: "true"

    metaMonitoring:
      dashboards:
        enabled: true
      serviceMonitor:
        enabled: true
        clusterLabel: homelab-cluster
      prometheusRule:
        enabled: true
        mimirAlerts: true
        mimirRules: true

    # Use the existing cluster S3 credentials (Garage) via env injection.
    global:
      extraEnvFrom:
        - secretRef:
            name: observability-s3

    # Run the built-in nginx gateway so clients can talk to a single endpoint.
    gateway:
      enabled: true
      replicas: 1
      service:
        type: ClusterIP
      resources:
        requests:
          cpu: 50m
          memory: 128Mi
        limits:
          cpu: 200m
          memory: 256Mi

    # Keep MinIO disabled; this cluster already has an S3-compatible object store.
    minio:
      enabled: false

    kafka:
      persistence:
        # StatefulSet volumeClaimTemplates are immutable.
        # NOTE: shrinking an existing PVC is not supported by Kubernetes.
        # To go from 40Gi -> 10Gi you must delete/recreate the PVC (and Kafka StatefulSet).
        size: 10Gi
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: "1"
          memory: 2Gi
      extraEnv:
        # Cap on-disk log retention to prevent filling the PVC.
        # NOTE: retention.bytes applies per-partition; total disk usage can exceed this if there are many partitions.
        # We also force segment roll by time so retention can kick in even under low traffic.
        - name: KAFKA_LOG_RETENTION_BYTES
          value: "33554432" # 32Mi
        # The chart hard-codes KAFKA_LOG_RETENTION_HOURS=24; avoid duplicating that env var.
        # Kafka gives `log.retention.ms` precedence over hours/minutes.
        - name: KAFKA_LOG_RETENTION_MS
          value: "7200000" # 2h
        - name: KAFKA_LOG_SEGMENT_BYTES
          value: "134217728" # 128Mi
        - name: KAFKA_LOG_SEGMENT_MS
          value: "900000" # 15m
        - name: KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS
          value: "300000"
        - name: KAFKA_OFFSETS_RETENTION_MINUTES
          value: "1440" # 1d

      # Kafka runs with a read-only root filesystem; mount a writable logs directory.
      extraVolumes:
        - name: kafka-logs
          emptyDir: {}
      extraVolumeMounts:
        - name: kafka-logs
          mountPath: /opt/kafka/logs

    mimir:
      structuredConfig:
        # Use the same bucket for all Mimir storage types.
        common:
          storage:
            backend: s3
            s3:
              bucket_name: mimir
              endpoint: ${S3_ENDPOINT}
              access_key_id: ${S3_ACCESS_KEY_ID}
              secret_access_key: ${S3_SECRET_ACCESS_KEY}
              insecure: true
              bucket_lookup_type: path
              http:
                insecure_skip_verify: true

        # Enforce long-term retention via the compactor.
        limits:
          compactor_blocks_retention_period: 90d

        # Explicitly set key backends to S3 as well.
        blocks_storage:
          backend: s3
          storage_prefix: blocks
          s3:
            bucket_name: mimir
            endpoint: ${S3_ENDPOINT}
            access_key_id: ${S3_ACCESS_KEY_ID}
            secret_access_key: ${S3_SECRET_ACCESS_KEY}
            insecure: true
            bucket_lookup_type: path
            http:
              insecure_skip_verify: true

        ruler_storage:
          backend: s3
          storage_prefix: ruler
          s3:
            bucket_name: mimir
            endpoint: ${S3_ENDPOINT}
            access_key_id: ${S3_ACCESS_KEY_ID}
            secret_access_key: ${S3_SECRET_ACCESS_KEY}
            insecure: true
            bucket_lookup_type: path
            http:
              insecure_skip_verify: true

        alertmanager_storage:
          backend: s3
          storage_prefix: alertmanager
          s3:
            bucket_name: mimir
            endpoint: ${S3_ENDPOINT}
            access_key_id: ${S3_ACCESS_KEY_ID}
            secret_access_key: ${S3_SECRET_ACCESS_KEY}
            insecure: true
            bucket_lookup_type: path
            http:
              insecure_skip_verify: true

        # Ingest storage uses Kafka topics; keep partition count sane.
        # Partition count MUST be >= max ingester replicas.
        ingest_storage:
          kafka:
            auto_create_topic_enabled: true
            auto_create_topic_default_partitions: 12

    # Ensure ingesters use Longhorn for WAL/data.
    ingester:
      replicas: 1
      persistentVolume:
        storageClass: longhorn
        size: 10Gi
      resources:
        requests:
          cpu: 200m
          memory: 768Mi
        limits:
          cpu: "1"
          memory: 2Gi

    store_gateway:
      replicas: 1
      persistentVolume:
        storageClass: longhorn
        size: 10Gi
      resources:
        requests:
          cpu: 100m
          memory: 256Mi
        limits:
          cpu: "1"
          memory: 1Gi

    compactor:
      replicas: 1
      persistentVolume:
        storageClass: longhorn
        size: 10Gi

      resources:
        requests:
          cpu: 100m
          memory: 512Mi
        limits:
          cpu: "1"
          memory: 1Gi

    distributor:
      replicas: 1
      resources:
        requests:
          cpu: 50m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 1Gi

    querier:
      replicas: 1
      resources:
        requests:
          cpu: 100m
          memory: 512Mi
        limits:
          cpu: "1"
          memory: 1Gi

    query_frontend:
      replicas: 1
      resources:
        requests:
          cpu: 50m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi

    ruler:
      replicas: 1
      resources:
        requests:
          cpu: 50m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi

    alertmanager:
      replicas: 1
      resources:
        requests:
          cpu: 50m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi
