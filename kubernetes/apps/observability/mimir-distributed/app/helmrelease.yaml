---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: mimir-distributed
spec:
  interval: 1h
  chart:
    spec:
      chart: mimir-distributed
      version: 6.0.5
      sourceRef:
        kind: HelmRepository
        name: grafana-charts-mimir
        namespace: observability
  values:
    podAnnotations:
      reloader.stakater.com/auto: "true"

    metaMonitoring:
      dashboards:
        enabled: true
      serviceMonitor:
        enabled: true
        clusterLabel: homelab-cluster
      prometheusRule:
        enabled: true
        mimirAlerts: true
        mimirRules: true

    # Use the existing cluster S3 credentials (Garage) via env injection.
    global:
      extraEnvFrom:
        - secretRef:
            name: observability-s3

    # Run the built-in nginx gateway so clients can talk to a single endpoint.
    gateway:
      enabled: true
      replicas: 1
      service:
        type: ClusterIP
      resources:
        requests:
          cpu: 50m
          memory: 128Mi
        limits:
          cpu: 200m
          memory: 256Mi

    # Keep MinIO disabled; this cluster already has an S3-compatible object store.
    minio:
      enabled: false

    kafka:
      persistence:
        storageClassName: longhorn
        size: 20Gi
      extraEnv:
        # Cap on-disk log retention to prevent filling the PVC.
        # NOTE: retention.bytes applies per-partition; total disk usage can exceed this if there are many partitions.
        # We also force segment roll by time so retention can kick in even under low traffic.
        - name: KAFKA_LOG_RETENTION_BYTES
          value: "2147483648" # 2Gi
        - name: KAFKA_LOG_RETENTION_HOURS
          value: "24"
        - name: KAFKA_LOG_SEGMENT_BYTES
          value: "268435456" # 256Mi
        - name: KAFKA_LOG_SEGMENT_MS
          value: "3600000" # 1h
        - name: KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS
          value: "300000"
        - name: KAFKA_OFFSETS_RETENTION_MINUTES
          value: "1440" # 1d

    mimir:
      structuredConfig:
        # Use the same bucket for all Mimir storage types.
        common:
          storage:
            backend: s3
            s3:
              bucket_name: mimir
              endpoint: ${S3_ENDPOINT}
              access_key_id: ${S3_ACCESS_KEY_ID}
              secret_access_key: ${S3_SECRET_ACCESS_KEY}
              insecure: true
              bucket_lookup_type: path
              http:
                insecure_skip_verify: true

        # Enforce long-term retention via the compactor.
        limits:
          compactor_blocks_retention_period: 90d

        # Explicitly set key backends to S3 as well.
        blocks_storage:
          backend: s3
          storage_prefix: blocks
          s3:
            bucket_name: mimir
            endpoint: ${S3_ENDPOINT}
            access_key_id: ${S3_ACCESS_KEY_ID}
            secret_access_key: ${S3_SECRET_ACCESS_KEY}
            insecure: true
            bucket_lookup_type: path
            http:
              insecure_skip_verify: true

        ruler_storage:
          backend: s3
          storage_prefix: ruler
          s3:
            bucket_name: mimir
            endpoint: ${S3_ENDPOINT}
            access_key_id: ${S3_ACCESS_KEY_ID}
            secret_access_key: ${S3_SECRET_ACCESS_KEY}
            insecure: true
            bucket_lookup_type: path
            http:
              insecure_skip_verify: true

        alertmanager_storage:
          backend: s3
          storage_prefix: alertmanager
          s3:
            bucket_name: mimir
            endpoint: ${S3_ENDPOINT}
            access_key_id: ${S3_ACCESS_KEY_ID}
            secret_access_key: ${S3_SECRET_ACCESS_KEY}
            insecure: true
            bucket_lookup_type: path
            http:
              insecure_skip_verify: true

    # Ensure ingesters use Longhorn for WAL/data.
    ingester:
      replicas: 1
      persistentVolume:
        storageClass: longhorn
        size: 10Gi
      resources:
        requests:
          cpu: 200m
          memory: 1Gi
        limits:
          cpu: "1"
          memory: 2Gi

    store_gateway:
      replicas: 1
      persistentVolume:
        storageClass: longhorn
        size: 10Gi
      resources:
        requests:
          cpu: 100m
          memory: 1Gi
        limits:
          cpu: "1"
          memory: 2Gi

    compactor:
      replicas: 1
      persistentVolume:
        storageClass: longhorn
        size: 10Gi

      resources:
        requests:
          cpu: 100m
          memory: 512Mi
        limits:
          cpu: "1"
          memory: 1Gi

    distributor:
      replicas: 1
      resources:
        requests:
          cpu: 50m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 1Gi

    querier:
      replicas: 1
      resources:
        requests:
          cpu: 100m
          memory: 512Mi
        limits:
          cpu: "1"
          memory: 1Gi

    query_frontend:
      replicas: 1
      resources:
        requests:
          cpu: 50m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi

    ruler:
      replicas: 1
      resources:
        requests:
          cpu: 50m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi

    alertmanager:
      replicas: 1
      resources:
        requests:
          cpu: 50m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi
